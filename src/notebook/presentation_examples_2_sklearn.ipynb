{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import autocorrect\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    'He playeed football',\n",
    "    'He plays cricket',\n",
    "    'He had sandwich for dinner'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summary (vectorizer, docs):\n",
    "    denseVector = vectorizer.fit_transform(docs).todense()\n",
    "    words = vectorizer.get_feature_names()\n",
    "    summary = pd.DataFrame(denseVector,columns = words, index = docs)\n",
    "    return summary\n",
    "    \n",
    "cv = CountVectorizer(lowercase = True)\n",
    "DTM = cv.fit_transform(docs).todense()\n",
    "words = cv.get_feature_names()\n",
    "summary = pd.DataFrame(DTM,columns = words, index = docs)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def process(doc):\n",
    "    s_doc = nlp(doc)\n",
    "    tokens = []\n",
    "    for token in s_doc:\n",
    "        #print(token, token.lemma_, token.pos_)\n",
    "        if(token.lemma_ == 'PRON' or token.lemma_ == '-PRON-'):\n",
    "            tokens.append(token.lower_)\n",
    "        else:\n",
    "            tokens.append(token.lemma_)    \n",
    "    #print (tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "class SpellTokenizer(object):\n",
    "    \n",
    "    def __init__(self, nlp):\n",
    "        self.vocab = nlp.vocab\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        doc = nlp.tokenizer(text)\n",
    "        words = [autocorrect.spell(i.orth_) for i in doc]\n",
    "        return spacy.tokens.Doc(self.vocab, words = words)\n",
    "\n",
    "nlp.make_doc = SpellTokenizer(nlp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(preprocessor = process)\n",
    "Summary(cv, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary(TfidfVectorizer(preprocessor = process), docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequencyâ€“Inverse Document Frequency (TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = [\n",
    "    'He playeed football',\n",
    "    'He plays cricket',\n",
    "    'He had sandwich for dinner',\n",
    "    'Sandwich i had for lunch was great',\n",
    "    \"He is neither a friend nor is he a foe\",    \n",
    "    \n",
    "]\n",
    "#Summary(CountVectorizer(preprocessor = process, ngram_range=(1, 3)), docs)\n",
    "\n",
    "#cv = CountVectorizer(preprocessor = process)\n",
    "#DTM = cv.fit_transform(docs).todense()\n",
    "#words = cv.get_feature_names()\n",
    "#summary = pd.DataFrame(DTM,columns = words, index = docs)\n",
    "#summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary(TfidfVectorizer(preprocessor = process, ngram_range=(1, 3)), docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarDocsCV(query, docs):\n",
    "    \n",
    "    vectorizer = CountVectorizer(preprocessor = process, ngram_range=(1, 2)) #CountVectorizer\n",
    "    dtm = vectorizer.fit_transform(docs).todense()\n",
    "    \n",
    "    query_vector = getVector(query, vectorizer)\n",
    "    similarities = computeSimilarities(query_vector, dtm)\n",
    "    mostSimilarDocIdx = getMostSimilarIdx(similarities)\n",
    "    return docs[mostSimilarDocIdx], mostSimilarDocIdx;\n",
    "\n",
    "def getSimilarDocsTfidf(query, docs):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(preprocessor = process, ngram_range=(1, 2)) #TfidfVectorizer\n",
    "    dtm = vectorizer.fit_transform(docs).todense()\n",
    "    \n",
    "    query_vector = getVector(query, vectorizer)\n",
    "    similarities = computeSimilarities(query_vector, dtm)\n",
    "    mostSimilarDocIdx = getMostSimilarIdx(similarities)\n",
    "    return docs[mostSimilarDocIdx], mostSimilarDocIdx;\n",
    "\n",
    "def getVector(query, vectorizer):\n",
    "    query_vector = vectorizer.transform([query]).todense()\n",
    "    return query_vector\n",
    "\n",
    "def computeSimilarities(query_vector, dtm):\n",
    "    all_vectors = np.concatenate((dtm, query_vector))\n",
    "    similarities = cosine_similarity(all_vectors)[-1][:-1]\n",
    "    return similarities\n",
    "\n",
    "def getMostSimilarIdx(similarities):\n",
    "    return np.argmax(similarities)\n",
    "\n",
    "def getLeastSimilarIdx(similarities):\n",
    "    return np.argmin(similarities)\n",
    "\n",
    "print(getSimilarDocsTfidf(\"dinner was awesome\", docs))\n",
    "print(getSimilarDocsCV(\"dinner was awesome\", docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    'Welcome to the weekly book review, my favorite' ,\n",
    "    'This isnt news, but the president discussed his favorite book',\n",
    "    'In the news today the president said',\n",
    "    'Obama stands by EPA about pollution',\n",
    "    'Obama against Wall street'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarDocsWordVector(query, docs):\n",
    "    dtm = list(map(lambda doc: nlp(doc).vector,  docs) )         # Word Vectors\n",
    "    query_vector = nlp(query).vector\n",
    "    all_vectors = dtm + [query_vector]\n",
    "    similarities = cosine_similarity(all_vectors)[-1][:-1]\n",
    "    mostSimilarDocIdx = getMostSimilarIdx(similarities)\n",
    "    return docs[mostSimilarDocIdx], mostSimilarDocIdx;\n",
    "\n",
    "#getSimilarDocsWordVector(\"President coal\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TFDIF Vector: \", getSimilarDocsTfidf(\"President coal\", docs))\n",
    "print(\"Count Vector: \", getSimilarDocsCV(\"President coal\", docs))\n",
    "print(\"Word Vector: \", getSimilarDocsWordVector(\"President coal\", docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(\"President\").vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(\"President\").vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"President coal\")\n",
    "doc2 = nlp(\"Obama stands by EPA about pollution\")\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
